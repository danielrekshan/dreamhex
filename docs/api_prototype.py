# -*- coding: utf-8 -*-
"""DreamHex | Dream to World.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JgE5SyIxSP28PlGD77un9OHLuNKYaIb_
"""

# @title 1. Setup & Load
!pip install -q diffusers transformers accelerate safetensors openai pydantic rembg onnxruntime-gpu imageio[ffmpeg]

import torch
import gc
import os
import getpass
import numpy as np
import math
import imageio
from diffusers import AutoPipelineForImage2Image
from PIL import Image
from IPython.display import display
from rembg import remove, new_session

# Clean up previous runs
if 'pipe' in globals(): del pipe
gc.collect()
torch.cuda.empty_cache()

print("‚è≥ Loading SDXL-Turbo...")
pipe = AutoPipelineForImage2Image.from_pretrained(
    "stabilityai/sdxl-turbo",
    torch_dtype=torch.float16,
    variant="fp16",
    low_cpu_mem_usage=True
).to("cuda")

pipe.enable_vae_slicing()
pipe.enable_vae_tiling()

print("‚è≥ Loading Background Remover...")
rembg_session = new_session("u2net")

print("‚úÖ System Ready.")

# @title 2. Generator (Token Safe & Seamless)
import torch.nn as nn

def generate_dream_scene(prompt_a, prompt_b=None, type="pano", frames=4):
    torch.cuda.empty_cache()

    # --- 1. THE SEAMLESS HACK (Model Patch) ---
    def make_seamless(model):
        for m in model.modules():
            if isinstance(m, nn.Conv2d):
                if type == "pano":
                    m.padding_mode = 'circular'
                else:
                    m.padding_mode = 'zeros'
        return model

    pipe.unet = make_seamless(pipe.unet)
    pipe.vae = make_seamless(pipe.vae)

    # --- STYLE CONSTANTS (Condensed for Token Safety) ---
    # ~8 Tokens
    style_header =  "Ink and watercolor, thick india ink lines,vintage paper texture, hazy."

    def build_full_prompt(raw_text, is_pano):
        if raw_text is None: raw_text = "void"

        # TRUNCATE: 15 words max (approx 20 tokens)
        safe_text = " ".join(raw_text.split()[:15])

        if is_pano:
            # ~15 Tokens
            # "14mm eye level 360 equirectangular panorama" does the heavy lifting for geometry
            return (
                style_header + safe_text +
                ", 360 equirectangular panorama, sepia"
            )
        else:
            # ~10 Tokens
            return (
                style_header + safe_text +
                ", isolated cutout on white, cel shaded, dynamic pose"
            )

    # --- CONFIG ---
    if type == "pano":
        width, height = 1024, 512
        # Negative prompts don't count towards the 77 token limit, so keep them detailed
        neg = "tilted, crooked, off-center, floor view, aerial, drone, people, animals, creatures, objects, items, spheres, focal point"
    else:
        width, height = 384, 384
        neg = "background, ground, shadow, tree, gradient, square, wall, floor, static"

    generated_images = []
    current_image = Image.new("RGB", (width, height), (255, 255, 255))

    print(f"üñåÔ∏è Generating {frames} frames for ({type})...")

    for i in range(frames):
        target_prompt = prompt_b if prompt_b else prompt_a

        # 1. LOGIC SELECTOR
        if type == "pano":
            current_raw = prompt_a
            strength = 1.0 if i == 0 else 0.4
        else:
            # Sprite Logic
            if i == 0: current_raw, strength = prompt_a, 1.0
            elif i == 1: current_raw, strength = prompt_a, 0.5
            elif i == 2: current_raw, strength = target_prompt, (0.7 if prompt_b else 0.5)
            else: current_raw, strength = target_prompt, (0.55 if prompt_b else 0.5)

        full_prompt = build_full_prompt(current_raw, type == "pano")

        # 2. GENERATE
        image = pipe(
            prompt=full_prompt,
            negative_prompt=neg,
            image=current_image,
            num_inference_steps=4,
            strength=strength,
            guidance_scale=0.0,
            width=width, height=height
        ).images[0]

        # 3. POST-PROCESS
        if type == "sprite":
            clean_img = remove(image, session=rembg_session)
            final_img = Image.new("RGB", clean_img.size, (255, 255, 255))
            final_img.paste(clean_img, (0, 0), clean_img)
            image = final_img

        generated_images.append(image)
        current_image = image

    return generated_images

# @title 3. The Dream Scryer (User Logic + Interactions)
from typing import List, Literal
from pydantic import BaseModel, Field
from openai import OpenAI
import os
import getpass
import re

if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API Key: ")
client = OpenAI()

# --- SYSTEM PROMPT (USER DEFINED) ---
SYSTEM_PROMPT = """
You are the Dream Scryer. You are trained in Central Image analysis by Hartmann. Map the dream to a Single Hex with 7 Stations, which represents the dream's central imagery.
### 1. Describe the CONTAINER (Background) ONLY, which is the setting of the central image as if it were a theatre backdrop.
### 2. Station 0 = Central Image. Stations 1-6 = Other entities.
- **Station 0 (Center):** The Central Image (Concrete Noun), which is the most important, bizarre, or emotional image of the dream.
- **Stations 1-6:** Important characters or objects. Only if explicitly in text.
    - Populate these with important entities from the text.
    - If the dream only has one subject, Stations 1-6 MUST be NULL.
    - *Example:* "Red balloon in empty room" -> Station 0="Balloon", Stations 1-6=NULL.
### 3. Provide 5 Interaction Options per entity.
- For every entity, provide **5 Distinct Interaction Options** for the player.
- Vary the tone: [Aggressive, Friendly, Inquisitive, Physical, Surreal].
- Examples: "Ask why they are sad", "Poke it with a stick", "Offer a gift".
- Short text (Max 6 words).

### 4. METADATA
- Generate a 'slug' (kebab-case) for file naming.

### OUTPUT
Return strictly structured JSON.
"""

# --- INTERACTION PROMPT ---
# Needed for the interaction test function
INTERACTION_PROMPT = """
You are the Dungeon Master. Calculate the entity's REACTION.
1. Output new animation prompts using **ACTIVE VERBS**.
2. Provide **5 NEW Interaction Options** based on the new emotional state.
"""

# --- STRICT MODELS ---
class Station(BaseModel):
    id: str = Field(..., description="ID")
    position_index: int = Field(..., description="0=Center")
    entity_name: str | None = Field(..., description="Name of Actor as a concrete noun")
    state_start: str | None = Field(..., description="Start: Actor + [Active Verb].")
    state_end: str | None = Field(..., description="End: Actor + [Active Verb].")
    entity_greeting: str | None = Field(..., description="Greeting.")
    interaction_options: List[str] = Field(..., min_items=5, max_items=5)

class DreamHex(BaseModel):
    title: str
    slug: str = Field(..., description="kebab-case-slug for filenames.") # Added for Batch Processor compatibility
    description_360: str = Field(..., description="Global setting. EMPTY. Max 10 words.")
    central_imagery: str = Field(..., description="Paragraph about the central image of the dream, written as dream analyst skilled in Hartmann's central image analysis.")
    stations: List[Station]

class DreamGenerationResponse(BaseModel):
    hex: DreamHex
    summary: str

# Needed for cell 4/5 interactions
class InteractionResponse(BaseModel):
    new_state_start: str
    new_state_end: str
    new_greeting: str
    new_options: List[str]

def analyze_dream(dream_text):
    print(f"üîÆ Scrying dream: '{dream_text[:30]}...'")
    try:
        completion = client.beta.chat.completions.parse(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": SYSTEM_PROMPT}, {"role": "user", "content": dream_text}],
            response_format=DreamGenerationResponse,
        )
        data = completion.choices[0].message.parsed

        # Sanitize slug
        data.hex.slug = re.sub(r'[^a-z0-9-]', '', data.hex.slug.lower())

        print(f"   [Slug]: {data.hex.slug}")
        print(f"   [BG Prompt]: {data.hex.description_360}")
        if data.hex.stations[0].entity_name:
             print(f"   [Center Entity]: {data.hex.stations[0].entity_name}")
        return data
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return None

def analyze_interaction(entity_name, current_state, user_command):
    print(f"üß† Calculating reaction for {entity_name}...")
    try:
        query = f"Entity: {entity_name} ({current_state}). User Action: {user_command}"
        completion = client.beta.chat.completions.parse(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": INTERACTION_PROMPT}, {"role": "user", "content": query}],
            response_format=InteractionResponse,
        )
        return completion.choices[0].message.parsed
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return None

# @title 4. Helper Functions (Sprite Sheets & Video)

def create_sprite_sheet(image_list, filename="sheet.png", cols=None):
    """
    Stitches a list of images into a single grid (Sprite Sheet).
    """
    if not image_list: return None

    # 1. Calculate Grid
    count = len(image_list)
    width, height = image_list[0].size
    if cols is None:
        cols = math.ceil(math.sqrt(count))
    rows = math.ceil(count / cols)

    # 2. Create Canvas
    sheet_width = cols * width
    sheet_height = rows * height
    sheet = Image.new("RGBA", (sheet_width, sheet_height))

    # 3. Paste Images
    for index, img in enumerate(image_list):
        row = index // cols
        col = index % cols
        x = col * width
        y = row * height
        sheet.paste(img, (x, y))

    # 4. Save
    sheet.save(filename)
    return {
        "filename": filename,
        "cols": cols,
        "rows": rows,
        "count": count
    }

def create_mp4(image_list, filename="background.mp4", fps=8):
    """
    Creates a looped MP4 from images.
    Uses a 'boomerang' loop (1-2-3-2-1) to make it seamless.
    """
    # Create a boomerang sequence for smooth looping
    # [0, 1, 2, 3] -> [0, 1, 2, 3, 2, 1]
    boomerang = image_list + image_list[-2:0:-1]

    writer = imageio.get_writer(filename, fps=fps, format='FFMPEG')

    for img in boomerang:
        # Convert PIL to Numpy Array for ImageIO
        frame = np.array(img)
        writer.append_data(frame)

    writer.close()
    return filename

# @title 5. Run DreamHex (Image Sequence Mode)
from IPython.display import display, Image as IPImage

current_hex_state = None
generated_asset_metadata = {}

def materialize_hex(user_report):
    global current_hex_state, generated_asset_metadata

    generated_asset_metadata = {}

    dream_data = analyze_dream(user_report)
    if not dream_data: return
    current_hex_state = dream_data

    print(f"\n‚ú® Dream Title: {dream_data.hex.title}")
    print(dream_data.hex)
    # --- 1. BACKGROUND (Image Sequence) ---
    print(f"\n--- BACKGROUND ---")
    print(dream_data.hex.description_360)

    # Generate 6 frames for a nice loop
    pano_frames = generate_dream_scene(dream_data.hex.description_360, type="pano", frames=6)

    # Save individual frames
    bg_filenames = []
    for i, img in enumerate(pano_frames):
        fname = f"background_{i}.jpg"
        img.save(fname, quality=80) # JPEG is smaller than PNG for full backgrounds
        display(IPImage(filename=fname, width=150))

        bg_filenames.append(fname)

    # Store this list in our Sidecar Metadata
    generated_asset_metadata["background"] = bg_filenames
    print(f"üé¨ Generated {len(bg_filenames)} background frames.")

    # --- 2. ENTITIES (Sprite Sheets) ---
    print("\n--- ENTITIES ---")
    sorted_stations = sorted(dream_data.hex.stations, key=lambda x: x.position_index)

    for station in sorted_stations:
        if not station.entity_name: continue

        print(f"\nüìç STATION {station.position_index}: {station.entity_name}")
        print(f"\nüìç action {station.state_start} - {station.state_end}")

        frame_list = generate_dream_scene(
            prompt_a=station.state_start,
            prompt_b=station.state_end,
            type="sprite",
            frames=4
        )

        sheet_filename = f"station_{station.position_index}.png"
        meta = create_sprite_sheet(frame_list, sheet_filename, cols=2)

        generated_asset_metadata[station.position_index] = meta

        print(f"   Saved {sheet_filename}")
        display(IPImage(filename=sheet_filename, width=150))

# --- TEST ---
materialize_hex("I was by a big tree near a river.  an old man was teaching me about words and dreams.  there was a castle down stream.")

# @title 6. Batch Process & Export (Slugged Sequences)
import json
import shutil
import os
from google.colab import files

# --- CONFIGURATION ---
DREAM_BATCH = [
    # Dream 1: The Mountain
    """I was in the mountains with my husband, and we were trying to hide behind
    some kind of camo-ish sheets and people were shooting up towards us.""",

    # Dream 2: The Flying
    """I realized I was dreaming and jumped off a balcony. Instead of falling,
    I turned into a golden eagle and flew over a city made of glass.""",

    # Dream 3: The Object
    """I found an antique wooden box in my grandmother's attic. When I opened it,
    an infinite staircase spiraled out of it into the sky."""
]

# --- HELPER: SAVE FRAMES ---
def save_frame_sequence(image_list, folder_path, file_prefix, file_format="PNG"):
    """
    Saves images as {file_prefix}_0.png, {file_prefix}_1.png...
    Returns relative paths for JSON.
    """
    saved_paths = []

    for i, img in enumerate(image_list):
        filename = f"{file_prefix}_{i}.{file_format.lower()}"
        full_path = os.path.join(folder_path, filename)

        if file_format == "JPEG":
            img.convert("RGB").save(full_path, quality=85)
        else:
            img.save(full_path, format="PNG")

        # Store relative path: "assets/dream-slug/slug_station_0_0.png"
        relative_path = os.path.join("assets", os.path.basename(folder_path), filename)
        saved_paths.append(relative_path)

    return saved_paths

def run_batch_processor():
    base_dir = "dream_export"
    assets_dir = os.path.join(base_dir, "assets")

    if os.path.exists(base_dir): shutil.rmtree(base_dir)
    os.makedirs(assets_dir)

    world_manifest = []

    print(f"üè≠ Starting Batch Process for {len(DREAM_BATCH)} dreams...")

    for i, dream_text in enumerate(DREAM_BATCH):
        # A. BRAIN
        analysis = analyze_dream(dream_text)
        if not analysis: continue

        # Use SLUG for folder and ID
        slug = analysis.hex.slug
        dream_folder = os.path.join(assets_dir, slug)
        os.makedirs(dream_folder, exist_ok=True)

        print(f"\n--- PROCESSING {slug.upper()} ---")

        dream_json = analysis.hex.model_dump()
        dream_json['id'] = slug # Use slug as ID
        dream_json['original_text'] = dream_text

        # B. HANDS: Background
        print(f"   üé® Generating Background Sequence...")
        bg_frames = generate_dream_scene(
            prompt_a=analysis.hex.description_360,
            type="pano",
            frames=3
        )

        # Naming: "mountain-chase_bg_0.jpg"
        bg_paths = save_frame_sequence(bg_frames, dream_folder, f"{slug}_bg", "JPEG")
        dream_json['background_frames'] = bg_paths

        # C. HANDS: Entities
        print(f"   üßö Generating Entity Sequences...")
        updated_stations = []

        for station in analysis.hex.stations:
            if not station.entity_name or not station.state_start:
                updated_stations.append(station.model_dump())
                continue

            print(f"      - Station {station.position_index}: {station.entity_name}")

            sprite_frames = generate_dream_scene(
                prompt_a=station.state_start,
                prompt_b=station.state_end,
                type="sprite",
                frames=4
            )

            # Naming: "mountain-chase_station_0_0.png"
            prefix = f"{slug}_station_{station.position_index}"
            sprite_paths = save_frame_sequence(sprite_frames, dream_folder, prefix, "PNG")

            station_dict = station.model_dump()
            station_dict['sprite_frames'] = sprite_paths
            updated_stations.append(station_dict)

        dream_json['stations'] = updated_stations
        world_manifest.append(dream_json)

    # 3. SAVE MANIFEST
    manifest_path = os.path.join(base_dir, "manifest.json")
    with open(manifest_path, "w") as f:
        json.dump(world_manifest, f, indent=2)

    print(f"\n‚úÖ Batch Complete! Saved {len(world_manifest)} dreams.")
    print("üì¶ Zipping assets...")
    shutil.make_archive("dream_world_pack", 'zip', base_dir)
    files.download("dream_world_pack.zip")

# --- RUN IT ---
run_batch_processor()