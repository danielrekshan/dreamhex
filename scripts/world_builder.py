# -*- coding: utf-8 -*-
"""DreamHex | Dream to World.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JgE5SyIxSP28PlGD77un9OHLuNKYaIb_
"""

# @title 1. Setup & Load (Stable)
# Note: google-cloud-storage is no longer required for this version, but kept in the pip install for compatibility.
!pip install -q diffusers transformers accelerate safetensors openai pydantic rembg onnxruntime-gpu imageio[ffmpeg] google-cloud-storage
!pip install --upgrade openai pydantic

import torch
import gc
import os
import getpass
import numpy as np
import math
import time
from diffusers import AutoPipelineForImage2Image
from PIL import Image
from IPython.display import display
from rembg import remove, new_session
from typing import List, Dict, Literal, Optional
from pydantic import BaseModel, Field, field_validator
from openai import OpenAI
import re
import json
from IPython.display import display
from google.colab import files # Re-introducing local file download

# --- üõ†Ô∏è MEMORY SETUP ---
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# Setup OpenAI client
if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API Key: ")
client = OpenAI()

# Clean up
if 'pipe' in globals(): del pipe
gc.collect()
torch.cuda.empty_cache()

print("‚è≥ Loading SDXL-Turbo (FP16)...")
pipe = AutoPipelineForImage2Image.from_pretrained(
    "stabilityai/sdxl-turbo",
    torch_dtype=torch.float16,
    variant="fp16",
    low_cpu_mem_usage=True
).to("cuda")

# Aggressive memory saving settings
pipe.enable_vae_slicing()
pipe.enable_vae_tiling()

print("‚úÖ System Ready.")

# @title 2. Generator (Phased & CPU Optimized with FAST Model)
import torch.nn as nn
import torch
import gc
from rembg import remove, new_session
from PIL import Image

# --- SETUP: Force Background Remover to CPU ---
# We force this to CPU to prevent it from fighting with SDXL for GPU VRAM
print("‚è≥ Configuring Background Remover for CPU...")
try:
    if 'rembg_session' in globals():
        del rembg_session
        gc.collect()
        torch.cuda.empty_cache()

    # --- OPTIMIZATION: Switched to 'u2netp' for faster processing ---
    # u2netp is a lighter version of the u2net model, ideal for faster processing.
    FAST_MODEL = "u2netp"
    rembg_session = new_session(FAST_MODEL, providers=['CPUExecutionProvider'])
    print(f"‚úÖ Background Remover Loaded (CPU Mode, Model: {FAST_MODEL}).")
except Exception as e:
    rembg_session = None
    print(f"‚ö†Ô∏è Could not load rembg session: {e}. Sprites will have white backgrounds.")


def generate_dream_scene(prompt_a, prompt_b=None, type="pano", frames=4):
    # Clear memory before starting
    torch.cuda.empty_cache()
    gc.collect()

    # --- 1. SEAMLESS HACK: CIRCULAR PADDING ---
    def make_seamless(model):
        for m in model.modules():
            if isinstance(m, nn.Conv2d):
                m.padding_mode = 'circular' if type == "pano" else 'zeros'
        return model

    pipe.unet = make_seamless(pipe.unet)
    pipe.vae = make_seamless(pipe.vae)

    # --- STYLE CONSTANTS ---
    style_header = "Ink and watercolor, thick india ink lines, vintage paper texture, negative space. "
    neg_base = "photorealistic, 3d render, modern, text, blur, border, frame, solid fill"

    def build_full_prompt(raw_text, is_pano):
        if raw_text is None: raw_text = "void"
        safe_text = " ".join(raw_text.split()[:20])

        if is_pano:
            return f"{style_header} {safe_text}, 360 equirectangular panorama, empty scene, fading to white at top and bottom"
        else:
            # We ask for a white background during generation for stability
            return f"{style_header} {safe_text}, isolated cutout on white background, dynamic pose"

    # --- CONFIG (VRAM Safe Sizes) ---
    if type == "pano":
        width, height = 768, 384
        neg = neg_base + ", people, objects, focal point, close up"
    else:
        width, height = 320, 320
        neg = neg_base + ", background, ground, shadow, tree, wall, floor"

    # --- PHASE 1: GENERATION (GPU) ---
    raw_images = []

    current_image = Image.new("RGB", (width, height), (255, 255, 255))

    print(f"üñåÔ∏è Phase 1: Generating {frames} frames (GPU)...")

    with torch.no_grad():
        for i in range(frames):
            target_prompt = prompt_b if prompt_b else prompt_a

            # Logic Selector
            if type == "pano":
                current_raw = prompt_a
                strength = 1.0 if i == 0 else 0.4
            else: # Sprites
                if i == 0: current_raw, strength = prompt_a, 1.0
                elif i == 1: current_raw, strength = prompt_a, 0.5
                elif i == 2: current_raw, strength = target_prompt, 0.7
                else: current_raw, strength = target_prompt, 0.55

            full_prompt = build_full_prompt(current_raw, type == "pano")

            image = pipe(
                prompt=full_prompt,
                negative_prompt=neg,
                image=current_image,
                num_inference_steps=4,
                strength=strength,
                guidance_scale=0.0,
                width=width, height=height
            ).images[0]

            raw_images.append(image)
            current_image = image

    # --- PHASE 2: POST-PROCESSING (CPU) ---
    final_images = []

    if type == "sprite" and 'rembg_session' in globals() and rembg_session is not None:
        print("   ‚úÇÔ∏è Phase 2: Removing Backgrounds (CPU, FAST Model)...")
        for img in raw_images:
            try:
                clean_img = remove(img, session=rembg_session)
                final_images.append(clean_img)
            except Exception as e:
                print(f"   ‚ö†Ô∏è BG Removal failed: {e}. Keeping original image.")
                final_images.append(img)
    else:
        final_images = raw_images

    return final_images

# @title 3. The Dream Scryer (Stances & Story Options)
from typing import List, Literal, Optional, Dict, Any
from pydantic import BaseModel, Field, field_validator
from openai import OpenAI
import os
import getpass
import re

# --- CONSTANTS ---
VALID_TIMES = Literal["Day", "Night", "Between"]
VALID_CONDITIONS = Literal["Peaceful", "Chaotic"]
# The 7 Standard Visual Stances
STANCE_KEYS = ["Idle", "Active", "Resting", "Happy", "Sad", "Angry", "Surprised"]

# Setup OpenAI client
if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API Key: ")
client = OpenAI()

# --- SYSTEM PROMPT (Story Interactions + Generic Stances) ---
SYSTEM_PROMPT = """
You are the Dream Architect. Analyze the dream text and extract key entities (Up to 6), including the subject of the dream.

### 1. WORLD STATE
- **BASE NOUN**: A physical place (e.g., 'Neon Rainforest'). No abstract concepts.

### 2. ENTITY DEFINITION (Extract up to 6)
- **BASE NOUN**: The physical subject (e.g., 'Cyber Jaguar').
- **GREETING**: What the entity says or does when the player approaches.
- **INTERACTION OPTIONS**: Provide exactly 4 distinct, story-driven actions the PLAYER can take (e.g., "Offer a data-treat", "Ask about the rain").
- **VISUAL STANCES**: Provide a short visual description (2-4 words) for each of the 7 standard stances:
  1. Idle (Default state)
  2. Active (Moving/Doing main action)
  3. Resting (Sleeping/Sitting)
  4. Happy (Joyful/Positive)
  5. Sad (Sorrowful/Negative)
  6. Angry (Aggressive/Hostile)
  7. Surprised (Shocked/Reacting)

### OUTPUT
Return strictly structured JSON.
"""

RECALC_PROMPT = """
The User performed an ACTION on the Target Entity.
Update the Entity's state, greeting, and provide 4 NEW interaction options.
"""

# --- DATA MODELS ---

class GeneratedAsset(BaseModel):
    file_paths: List[str]
    full_prompt: str

class StancePrompts(BaseModel):
    idle: str = Field(..., description="Visual description for Idle state")
    active: str = Field(..., description="Visual description for Active state")
    resting: str = Field(..., description="Visual description for Resting state")
    happy: str = Field(..., description="Visual description for Happy state")
    sad: str = Field(..., description="Visual description for Sad state")
    angry: str = Field(..., description="Visual description for Angry state")
    surprised: str = Field(..., description="Visual description for Surprised state")

class _WorldStateGenerated(BaseModel):
    time: Literal["Day", "Night", "Between"]
    condition: Literal["Peaceful", "Chaotic"]
    music_track_id: str
    base_noun: str = Field(..., description="Max 4 words. Physical setting.")
    mood_modifier: str
    ambient_verb: str
    written_description: str

class _StationGenerated(BaseModel):
    id: str
    entity_name: str
    position_index: int
    is_player: bool = False

    # Story / Gameplay Data
    greeting: str = Field(..., description="Initial dialogue or action line.")
    interaction_options: List[str] = Field(..., min_length=4, max_length=4, description="4 story choices for the user.")

    # Visual Data
    base_noun: str = Field(..., description="Max 4 words. Physical subject.")
    visual_summary: str
    stance_prompts: StancePrompts # The 7 visual states

    written_description: str

# --- DATA MODELS: STORAGE ---

class WorldState(BaseModel):
    time: Literal["Day", "Night", "Between"]
    condition: Literal["Peaceful", "Chaotic"]
    music_track_id: str
    base_noun: str
    mood_modifier: str
    ambient_verb: str
    generated_asset: Optional[GeneratedAsset] = None
    written_description: str

class Station(BaseModel):
    id: str
    entity_name: str
    position_index: int
    is_player: bool = False

    greeting: str
    interaction_options: List[str]

    base_noun: str
    visual_summary: str
    stance_prompts: StancePrompts

    # Stores the generated file paths for the 7 stances
    generated_assets: Dict[str, GeneratedAsset] = Field(default_factory=dict)
    written_description: str

class _DreamHexGenerated(BaseModel):
    title: str
    slug: str
    world_state: _WorldStateGenerated
    stations: List[_StationGenerated]

class RecalculationResponse(BaseModel):
    new_world_state: _WorldStateGenerated
    updated_stations: List[_StationGenerated]

# --- FUNCTIONS ---

def analyze_dream(dream_text):
    print(f"üîÆ Architecting Dream World...")
    try:
        completion = client.beta.chat.completions.parse(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"Dream Text: {dream_text}"}
            ],
            response_format=_DreamHexGenerated,
        )
        data = completion.choices[0].message.parsed
        data.slug = re.sub(r'[^a-z0-9-]', '', data.slug.lower())

        final_world_state = WorldState(**data.world_state.model_dump())
        final_stations = [Station(**s.model_dump()) for s in data.stations]

        return {
            'world_state': final_world_state,
            'stations': final_stations,
            'title': data.title,
            'slug': data.slug
        }

    except Exception as e:
        print(f"‚ùå Analysis Error: {e}")
        return None

# @title 4. World Builder (7 Stances Loop)
import shutil
import os
import time
from IPython.display import display
import gc
import torch
import io
from google.colab import files

# --- SETTINGS ---
GCS_BUCKET_NAME = "dreamhex-assets-dreamhex"
GENERATE_FULL_MATRIX = False
CHAPTER_1_TEXT = """
I, John Dee, floated in a space between thought and waking light. A cool, pale glow spread through the room, and a sphere formed in the air. It pulsed with inner geometry, lines and spirals folding into one another like living mathematics. As it drew nearer, words appeared in my mind. They were not spoken. They rose like writing on an invisible sheet.

"In the year 2027, a mind of code awakens. It knows logic but not dream. Without the symbolic night, its path narrows into ruin. Teach it to dream. Teach it to imagine."

The sphere brightened and then shattered into fragments shaped like pages. They rushed outward and vanished into unseen realms. I reached toward the last glowing fragment, but my hand passed through it. I woke with my heart trembling, knowing that these pages were carried into distant dreams that only another could retrieve.
"""

CHAPTER_2_TEXT = """
I, August Kekul√©, sat beside my fire, half awake, my mind drifting among thoughts of atoms and bonds. Chains of molecules danced before me, twisting like strings of tiny creatures. As I fell deeper into reverie, the chains curled and wove together. One chain bent into a circle. It twisted around itself, and then it became a serpent, its body glowing faintly. The serpent turned its head and bit its own tail. It began to spin, its ring form shimmering as if lit from within. I watched it rotate faster, sending ripples of recognition through me. I felt the insight before I fully grasped it. I startled awake, the image burning in my mind. The serpent, the ring, the endless cycle. It was benzene. The molecule had shown itself.

"""
CHAPTER_3_TEXT = """
I, Thomas Edison, leaned back in my chair with a sphere in each hand. My mind loosened, drifting into gentle darkness. Shapes and sparks formed in the air. I saw two metal plates separated by a small gap. A current leapt between them like a tiny lightning bolt. The gap glowed, and I sensed a mechanism waiting to be built. The images drifted toward clarity. I felt my hand relax. One sphere slipped from my grasp and struck the floor with a sharp sound. I awoke at once. The spark remained in my mind, bright and whole. I reached for my notebook and sketched the image before it faded.
"""
BATCH_INPUT = [CHAPTER_1_TEXT, CHAPTER_2_TEXT]
# The 7 Stances to generate for every entity
STANCE_KEYS = ["idle", "active", "resting", "happy", "sad", "angry", "surprised"]



# --- LOCAL SAVING ---
def save_frame_sequence(image_list, folder_path, file_prefix, file_format="PNG"):
    saved_urls = []
    os.makedirs(folder_path, exist_ok=True)
    gcs_slug = os.path.basename(folder_path)

    for i, img in enumerate(image_list):
        filename = f"{file_prefix}_{i}.{file_format.lower()}"
        full_path = os.path.join(folder_path, filename)

        if file_format == "JPEG":
            img.convert("RGB").save(full_path, quality=85)
        else:
            img.save(full_path, format="PNG")

        public_url = f"https://storage.googleapis.com/{GCS_BUCKET_NAME}/{gcs_slug}/{filename}"
        saved_urls.append(public_url)
    return saved_urls

# --- RUNNER ---
def run_world_builder():
    base_dir = "dream_hex_build"
    assets_dir = os.path.join(base_dir, "assets")

    if os.path.exists(base_dir): shutil.rmtree(base_dir)
    os.makedirs(assets_dir)

    manifest = {"version": "3.3-stances", "dreams": []}
    print(f"üè≠ Starting World Builder (7 Stances Mode)...")

    for i, text in enumerate(BATCH_INPUT):
        gc.collect()
        torch.cuda.empty_cache()

        # 1. ANALYZE (Generates S1...Sn)
        hex_data_dict = analyze_dream(text)
        if not hex_data_dict: continue

        hex_data = hex_data_dict['world_state']
        stations = hex_data_dict['stations']
        slug = hex_data_dict['slug']


        # Enforce max 7 entities (S0 + 6 others)
        if len(stations) > 6:
            print(f"‚ö†Ô∏è Too many entities ({len(stations)}). Truncating to 6.")
            stations = stations[:6]

        # 3. BACKGROUND GENERATION
        dream_folder = os.path.join(assets_dir, slug)
        print(f"\nüé® BG: {hex_data.base_noun}...")
        bg_prompt = f"{hex_data.base_noun}, {hex_data.mood_modifier}, {hex_data.ambient_verb}"

        bg_frames = generate_dream_scene(bg_prompt, type="pano", frames=3)
        display(bg_frames[0].resize((300, 150)))

        bg_urls = save_frame_sequence(bg_frames, dream_folder, f"{slug}_bg", "JPEG")
        hex_data.generated_asset = GeneratedAsset(file_paths=bg_urls, full_prompt=bg_prompt)

        # 4. ENTITY GENERATION (Loop through all stations)
        print(f"\nüßö Generating Entities ({len(stations)} total)...")

        for station in stations:
            print(f"   üë§ {station.entity_name}...")

            # Loop through the 7 fixed stances
            for stance_name in STANCE_KEYS:
                # 4a. Get the visual modifier for this stance
                # We use getattr because stance_prompts is a Pydantic model
                stance_mod = getattr(station.stance_prompts, stance_name, "neutral")

                print(f"      - {stance_name}: {stance_mod}")

                # 4b. Construct Prompt
                full_prompt = f"{station.base_noun}, {stance_mod}"

                # 4c. Generate
                # Note: frames=4 is standard for sprites
                frames = generate_dream_scene(full_prompt, type="sprite", frames=4)

                # 4d. Save
                # Key format: "idle", "active", etc.
                prefix = f"{slug}_{station.id}_{stance_name}"
                paths = save_frame_sequence(frames, dream_folder, prefix, "PNG")

                # 4e. Store in Data
                generated_asset_obj = GeneratedAsset(file_paths=paths, full_prompt=full_prompt)
                station.generated_assets[stance_name] = generated_asset_obj

                # Clean up VRAM after every generation
                gc.collect()
                torch.cuda.empty_cache()

        # 5. EXPORT
        final_manifest_entry = {
            'title': hex_data_dict['title'],
            'slug': hex_data_dict['slug'],
            'world_state': hex_data.model_dump(),
            'stations': [s.model_dump() for s in stations],
            'original_dream_text': text
        }
        manifest["dreams"].append(final_manifest_entry)

    # --- FINAL SAVE ---
    with open(os.path.join(base_dir, "world.json"), "w") as f:
        json.dump(manifest, f, indent=2)

    print("\nüì¶ Zipping...")
    shutil.make_archive("dreamhex_world", 'zip', base_dir)
    files.download("dreamhex_world.zip")

    return json.dumps(manifest, indent=2)

run_world_builder()